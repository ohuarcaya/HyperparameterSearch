{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./lib/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lib.Methods import GeneralMethods\n",
    "from lib.edasSearch import EdasHyperparameterSearch\n",
    "from lib.Hiperparametros import HyperparameterSwitcher\n",
    "from lib.ImportacionModelos import getClassifierNames\n",
    "from lib.ImportacionModelos import getClassifierModels\n",
    "from lib.ImportacionModelos import getRegressorNames\n",
    "from lib.ImportacionModelos import getRegressorModels\n",
    "from lib.graphicGenerator import GraphicBuilder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Distribución de data 80% data para entrenamiento y 20% para validación__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "seed = 9\n",
    "xSize = 1055\n",
    "kf = KFold(n_splits=10)\n",
    "df = pd.read_csv(\"data/filtred.csv\")\n",
    "X = df[df.columns[:xSize]]\n",
    "Y = df[df.columns[xSize:]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "gbTrain = GraphicBuilder(pd.concat([X_train, y_train],axis=1))\n",
    "gbTest = GraphicBuilder(pd.concat([X_test, y_test],axis=1))\n",
    "# x_trainReg = pd.concat([X, Y[['BUILDINGID', 'FLOOR']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_building = []\n",
    "l_floor = []\n",
    "l_latitude = []\n",
    "l_longitude = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nidModelo = 0\\nmodelName = modelNameList[idModelo]\\n# hypSwitcher = HyperparameterSwitcher(modelName)\\nestimador = estimadorDictionary[modelName]\\n# parametros = hypSwitcher.getHyperparameters()()\\n# searchParams = hypSwitcher.getHeurisctics()()\\n# estimador.fit(X_train, y_train.BUILINDINGID)\\n# p_building = estimador.predict(X_test)\\n\\nscoreBuilding = cross_validate(estimador, X_train, y_train.BUILDINGID, scoring=scoring_acc, cv=kf, return_train_score=False)\\nscoreFloor = cross_validate(estimador, X_train, y_train.FLOOR, scoring=scoring_acc, cv=kf, return_train_score=False)\\npd.DataFrame(scoreBuilding).to_csv(\"result/_building/\" + modelName + \".csv\", index=False)\\npd.DataFrame(scoreFloor).to_csv(\"result/_floor/\" + modelName + \".csv\", index=False)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arg1 = int(sys.argv[1]) # 0:randomized, 1:exhaustive, 2:edas, 3:eas\n",
    "# arg2 = int(sys.argv[2]) # 0:FLOOR, 1:BUILDINGID, 2:LATITUDE, 3:LONGITUDE\n",
    "# arg3 = int(sys.argv[3]) # 0 al 17 (classifier) 0 al 13 (regressor)\n",
    "# arg4 = 0 # 1:classifier, 0: regression\n",
    "#arg4 = True if arg2<=1 else False\n",
    "#listProcess = [\"randomized\", \"exhaustive\", \"edas\", \"eas\"]\n",
    "#listPredict = [\"FLOOR\", \"BUILDINGID\", \"LATITUDE\", \"LONGITUDE\"]\n",
    "\n",
    "\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "modelNameList = getClassifierNames(includeEnsambled=True)\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def accert(y_true, y_pred): \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return (cm.diagonal()/cm.sum(0)).mean()\n",
    "\n",
    "scoring_acc = {\n",
    "    #'average_precision' : 'average_precision_weighted',\n",
    "    #'precision': 'precision',\n",
    "    #'recall': 'recall',\n",
    "    #'balanced_accuracy': 'balanced_accuracy',\n",
    "    #'roc_auc': 'roc_auc',\n",
    "    'nbaccuracy' : make_scorer(accert),\n",
    "    'accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "#\"\"\"\n",
    "for idModelo in range(18):\n",
    "    modelName = modelNameList[idModelo]\n",
    "    estimador = estimadorDictionary[modelName]\n",
    "    scoreBuilding = cross_validate(estimador, X_train, y_train.BUILDINGID, scoring=scoring_acc, cv=kf, return_train_score=False)\n",
    "    scoreFloor = cross_validate(estimador, X_train, y_train.FLOOR, scoring=scoring_acc, cv=kf, return_train_score=False)\n",
    "    pd.DataFrame(scoreBuilding).to_csv(\"result/_building/\" + modelName + \".csv\", index=False)\n",
    "    pd.DataFrame(scoreFloor).to_csv(\"result/_floor/\" + modelName + \".csv\", index=False)\n",
    "    l_building.append(scoreBuilding)\n",
    "    l_floor.append(scoreFloor)\n",
    "\"\"\"\n",
    "idModelo = 0\n",
    "modelName = modelNameList[idModelo]\n",
    "# hypSwitcher = HyperparameterSwitcher(modelName)\n",
    "estimador = estimadorDictionary[modelName]\n",
    "# parametros = hypSwitcher.getHyperparameters()()\n",
    "# searchParams = hypSwitcher.getHeurisctics()()\n",
    "# estimador.fit(X_train, y_train.BUILINDINGID)\n",
    "# p_building = estimador.predict(X_test)\n",
    "\n",
    "scoreBuilding = cross_validate(estimador, X_train, y_train.BUILDINGID, scoring=scoring_acc, cv=kf, return_train_score=False)\n",
    "scoreFloor = cross_validate(estimador, X_train, y_train.FLOOR, scoring=scoring_acc, cv=kf, return_train_score=False)\n",
    "pd.DataFrame(scoreBuilding).to_csv(\"result/_building/\" + modelName + \".csv\", index=False)\n",
    "pd.DataFrame(scoreFloor).to_csv(\"result/_floor/\" + modelName + \".csv\", index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nidModelo = 0\\nmodelName = modelNameList[idModelo]\\n# hypSwitcher = HyperparameterSwitcher(modelName)\\nestimador = estimadorDictionary[modelName]\\n\\nscoreLat = cross_validate(estimador, x_trainReg, y_train.LATITUDE, scoring=scoring_reg, cv=kf, return_train_score=False)\\nscoreLon = cross_validate(estimador, x_trainReg, y_train.LONGITUDE, scoring=scoring_reg, cv=kf, return_train_score=False)\\npd.DataFrame(scoreLat).to_csv(\"result/_latitude/\" + modelName + \".csv\", index=False)\\npd.DataFrame(scoreLon).to_csv(\"result/_longitude/\" + modelName + \".csv\", index=False)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics as scoreMetrics\n",
    "import geopy.distance\n",
    "from functools import reduce\n",
    "\n",
    "x_trainReg = pd.concat([X_train, y_train[['BUILDINGID']]], axis=1) # , 'FLOOR'\n",
    "\n",
    "_meanLat = 39.9926853\n",
    "_meanLon = -0.0673033\n",
    "_minLongitude = -7705\n",
    "_maxLongitude = -7290\n",
    "_minLatitude = 4864735\n",
    "_maxLatitude = 4865023\n",
    "_maxLatitudeGPS = 39.993720\n",
    "_maxLongitudeGPS = -0.069254\n",
    "_minLatitudeGPS = 39.991626\n",
    "_minLongitudeGPS = -0.065425\n",
    "\n",
    "def longitudeToGPS(x):\n",
    "    return (_maxLongitudeGPS - _minLongitudeGPS) * (x - _minLongitude) / (_maxLongitude - _minLongitude) + _minLongitudeGPS\n",
    "\n",
    "def latitudeToGPS(x):\n",
    "    return (_maxLatitudeGPS - _minLatitudeGPS) * (x - _minLatitude) / (_maxLatitude - _minLatitude) + _minLatitudeGPS\n",
    "\n",
    "def latitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "\n",
    "def longitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "    \n",
    "def distance2d(y_true, y_pred):\n",
    "    ldis = []\n",
    "    if ((y_true>0).sum()>0):\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "        ldis = latitudeListDistance(y_true, y_pred)\n",
    "    else:\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "        ldis = longitudeListDistance(y_true, y_pred)\n",
    "    return reduce(lambda x,y: x+y, ldis) / len(ldis)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return scoreMetrics.mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "def mae(y_true, y_pred):\n",
    "    return scoreMetrics.mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "scoring_reg = {\n",
    "    'mae': make_scorer(mae),# 'mean_absolute_error',\n",
    "    'mse': make_scorer(mse),#'mean_squared_error',\n",
    "    'distance': make_scorer(distance2d),\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "estimadorDictionary = getRegressorModels(includeEnsambled=True)\n",
    "modelNameList = getRegressorNames(includeEnsambled=True)\n",
    "\n",
    "\n",
    "for idModelo in range(14):\n",
    "    modelName = modelNameList[idModelo]\n",
    "    estimador = estimadorDictionary[modelName]\n",
    "    scoreLat = cross_validate(estimador, x_trainReg, y_train.LATITUDE, scoring=scoring_reg, cv=kf, return_train_score=False)\n",
    "    scoreLon = cross_validate(estimador, x_trainReg, y_train.LONGITUDE, scoring=scoring_reg, cv=kf, return_train_score=False)\n",
    "    pd.DataFrame(scoreLat).to_csv(\"result/_latitude/\" + modelName + \".csv\", index=False)\n",
    "    pd.DataFrame(scoreLon).to_csv(\"result/_longitude/\" + modelName + \".csv\", index=False)\n",
    "    l_latitude.append(scoreLat)\n",
    "    l_longitude.append(scoreLon)\n",
    "\"\"\"\n",
    "idModelo = 0\n",
    "modelName = modelNameList[idModelo]\n",
    "# hypSwitcher = HyperparameterSwitcher(modelName)\n",
    "estimador = estimadorDictionary[modelName]\n",
    "\n",
    "scoreLat = cross_validate(estimador, x_trainReg, y_train.LATITUDE, scoring=scoring_reg, cv=kf, return_train_score=False)\n",
    "scoreLon = cross_validate(estimador, x_trainReg, y_train.LONGITUDE, scoring=scoring_reg, cv=kf, return_train_score=False)\n",
    "pd.DataFrame(scoreLat).to_csv(\"result/_latitude/\" + modelName + \".csv\", index=False)\n",
    "pd.DataFrame(scoreLon).to_csv(\"result/_longitude/\" + modelName + \".csv\", index=False)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>2.272874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.105477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mae</th>\n",
       "      <td>7.024801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mse</th>\n",
       "      <td>89.337374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_distance</th>\n",
       "      <td>5.685750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.980692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LinearRegression\n",
       "fit_time               2.272874\n",
       "score_time             0.105477\n",
       "test_mae               7.024801\n",
       "test_mse              89.337374\n",
       "test_distance          5.685750\n",
       "test_r2                0.980692"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.DataFrame(scoreLat).mean(), columns=[modelName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogisticRegression',\n",
       " 'SGDClassifier',\n",
       " 'PassiveAggressiveClassifier',\n",
       " 'MLPClassifier',\n",
       " 'LinearDiscriminantAnalysis',\n",
       " 'QuadraticDiscriminantAnalysis',\n",
       " 'KNeighborsClassifier',\n",
       " 'DecisionTreeClassifier',\n",
       " 'GaussianNB',\n",
       " 'BernoulliNB',\n",
       " 'MultinomialNB',\n",
       " 'SVC',\n",
       " 'AdaBoostClassifier',\n",
       " 'GradientBoostingClassifier',\n",
       " 'RandomForestClassifier',\n",
       " 'ExtraTreesClassifier',\n",
       " 'VotingClassifier',\n",
       " 'BaggingClassifier']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getClassifierNames(includeEnsambled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLatitude = pd.DataFrame(pd.DataFrame(l_latitude[0]).mean(), columns=['LinearRegression'])\n",
    "dfLatitude['Lasso'] = pd.DataFrame(pd.DataFrame(l_latitude[1]).mean())\n",
    "dfLatitude['Ridge'] = pd.DataFrame(pd.DataFrame(l_latitude[2]).mean())\n",
    "dfLatitude['ElasticNet'] = pd.DataFrame(pd.DataFrame(l_latitude[3]).mean())\n",
    "dfLatitude['PassiveAggressiveRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[4]).mean())\n",
    "dfLatitude['SVR'] = pd.DataFrame(pd.DataFrame(l_latitude[5]).mean())\n",
    "dfLatitude['DecisionTreeRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[6]).mean())\n",
    "dfLatitude['KNeighborsRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[7]).mean())\n",
    "dfLatitude['GaussianProcessRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[8]).mean())\n",
    "dfLatitude['AdaBoostRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[9]).mean())\n",
    "dfLatitude['GradientBoostingRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[10]).mean())\n",
    "dfLatitude['RandomForestRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[11]).mean())\n",
    "dfLatitude['ExtraTreesRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[12]).mean())\n",
    "dfLatitude['BaggingRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[13]).mean())\n",
    "dfLatitude.to_csv(\"result/_latitude/Comparacion.csv\", index=False)\n",
    "\n",
    "dfLongitude = pd.DataFrame(pd.DataFrame(l_longitude[0]).mean(), columns=['LinearRegression'])\n",
    "dfLongitude['Lasso'] = pd.DataFrame(pd.DataFrame(l_longitude[1]).mean())\n",
    "dfLongitude['Ridge'] = pd.DataFrame(pd.DataFrame(l_longitude[2]).mean())\n",
    "dfLongitude['ElasticNet'] = pd.DataFrame(pd.DataFrame(l_longitude[3]).mean())\n",
    "dfLongitude['PassiveAggressiveRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[4]).mean())\n",
    "dfLongitude['SVR'] = pd.DataFrame(pd.DataFrame(l_longitude[5]).mean())\n",
    "dfLongitude['DecisionTreeRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[6]).mean())\n",
    "dfLongitude['KNeighborsRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[7]).mean())\n",
    "dfLongitude['GaussianProcessRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[8]).mean())\n",
    "dfLongitude['AdaBoostRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[9]).mean())\n",
    "dfLongitude['GradientBoostingRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[10]).mean())\n",
    "dfLongitude['RandomForestRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[11]).mean())\n",
    "dfLongitude['ExtraTreesRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[12]).mean())\n",
    "dfLongitude['BaggingRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[13]).mean())\n",
    "dfLongitude.to_csv(\"result/_longitude/Comparacion.csv\", index=False)\n",
    "\n",
    "dfFloor = pd.DataFrame(pd.DataFrame(l_floor[0]).mean(), columns=['LogisticRegression'])\n",
    "dfFloor['SGDClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[1]).mean())\n",
    "dfFloor['PassiveAggressiveClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[2]).mean())\n",
    "dfFloor['MLPClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[3]).mean())\n",
    "dfFloor['LinearDiscriminantAnalysis'] = pd.DataFrame(pd.DataFrame(l_floor[4]).mean())\n",
    "dfFloor['QuadraticDiscriminantAnalysis'] = pd.DataFrame(pd.DataFrame(l_floor[5]).mean())\n",
    "dfFloor['KNeighborsClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[6]).mean())\n",
    "dfFloor['DecisionTreeClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[7]).mean())\n",
    "dfFloor['GaussianNB'] = pd.DataFrame(pd.DataFrame(l_floor[8]).mean())\n",
    "dfFloor['BernoulliNB'] = pd.DataFrame(pd.DataFrame(l_floor[9]).mean())\n",
    "dfFloor['MultinomialNB'] = pd.DataFrame(pd.DataFrame(l_floor[10]).mean())\n",
    "dfFloor['SVC'] = pd.DataFrame(pd.DataFrame(l_floor[11]).mean())\n",
    "dfFloor['AdaBoostClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[12]).mean())\n",
    "dfFloor['GradientBoostingClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[13]).mean())\n",
    "dfFloor['RandomForestClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[14]).mean())\n",
    "dfFloor['ExtraTreesClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[15]).mean())\n",
    "dfFloor['VotingClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[16]).mean())\n",
    "dfFloor['BaggingClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[17]).mean())\n",
    "dfFloor.to_csv(\"result/_floor/Comparacion.csv\", index=False)\n",
    "\n",
    "dfBuilding = pd.DataFrame(pd.DataFrame(l_building[0]).mean(), columns=['LogisticRegression'])\n",
    "dfBuilding['SGDClassifier'] = pd.DataFrame(pd.DataFrame(l_building[1]).mean())\n",
    "dfBuilding['PassiveAggressiveClassifier'] = pd.DataFrame(pd.DataFrame(l_building[2]).mean())\n",
    "dfBuilding['MLPClassifier'] = pd.DataFrame(pd.DataFrame(l_building[3]).mean())\n",
    "dfBuilding['LinearDiscriminantAnalysis'] = pd.DataFrame(pd.DataFrame(l_building[4]).mean())\n",
    "dfBuilding['QuadraticDiscriminantAnalysis'] = pd.DataFrame(pd.DataFrame(l_building[5]).mean())\n",
    "dfBuilding['KNeighborsClassifier'] = pd.DataFrame(pd.DataFrame(l_building[6]).mean())\n",
    "dfBuilding['DecisionTreeClassifier'] = pd.DataFrame(pd.DataFrame(l_building[7]).mean())\n",
    "dfBuilding['GaussianNB'] = pd.DataFrame(pd.DataFrame(l_building[8]).mean())\n",
    "dfBuilding['BernoulliNB'] = pd.DataFrame(pd.DataFrame(l_building[9]).mean())\n",
    "dfBuilding['MultinomialNB'] = pd.DataFrame(pd.DataFrame(l_building[10]).mean())\n",
    "dfBuilding['SVC'] = pd.DataFrame(pd.DataFrame(l_building[11]).mean())\n",
    "dfBuilding['AdaBoostClassifier'] = pd.DataFrame(pd.DataFrame(l_building[12]).mean())\n",
    "dfBuilding['GradientBoostingClassifier'] = pd.DataFrame(pd.DataFrame(l_building[13]).mean())\n",
    "dfBuilding['RandomForestClassifier'] = pd.DataFrame(pd.DataFrame(l_building[14]).mean())\n",
    "dfBuilding['ExtraTreesClassifier'] = pd.DataFrame(pd.DataFrame(l_building[15]).mean())\n",
    "dfBuilding['VotingClassifier'] = pd.DataFrame(pd.DataFrame(l_building[16]).mean())\n",
    "dfBuilding['BaggingClassifier'] = pd.DataFrame(pd.DataFrame(l_building[17]).mean())\n",
    "dfBuilding.to_csv(\"result/_building/Comparacion.csv\", index=False)\n",
    "\n",
    "#pd.DataFrame(pd.DataFrame(l_building[0]).mean(), columns=[modelName])\n",
    "#l_floor\n",
    "#l_latitude\n",
    "#l_longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <th>SVR</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <th>BaggingRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>2.531144</td>\n",
       "      <td>1.054282</td>\n",
       "      <td>0.848534</td>\n",
       "      <td>0.898072</td>\n",
       "      <td>0.783983</td>\n",
       "      <td>348.231184</td>\n",
       "      <td>1.469077</td>\n",
       "      <td>1.982650</td>\n",
       "      <td>3.064316e+02</td>\n",
       "      <td>83.009644</td>\n",
       "      <td>38.564748</td>\n",
       "      <td>8.239344</td>\n",
       "      <td>9.545212</td>\n",
       "      <td>9.469980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.085233</td>\n",
       "      <td>0.081150</td>\n",
       "      <td>0.084967</td>\n",
       "      <td>0.084130</td>\n",
       "      <td>0.081812</td>\n",
       "      <td>154.376145</td>\n",
       "      <td>0.082450</td>\n",
       "      <td>31.751880</td>\n",
       "      <td>9.619912e+01</td>\n",
       "      <td>0.443865</td>\n",
       "      <td>0.166302</td>\n",
       "      <td>0.121974</td>\n",
       "      <td>0.135257</td>\n",
       "      <td>0.342275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mae</th>\n",
       "      <td>8.540289</td>\n",
       "      <td>19.371092</td>\n",
       "      <td>8.507692</td>\n",
       "      <td>32.831996</td>\n",
       "      <td>158.575941</td>\n",
       "      <td>63.791369</td>\n",
       "      <td>2.782402</td>\n",
       "      <td>3.806230</td>\n",
       "      <td>3.801109e+03</td>\n",
       "      <td>2.061294</td>\n",
       "      <td>8.871777</td>\n",
       "      <td>2.764245</td>\n",
       "      <td>2.540180</td>\n",
       "      <td>2.742543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mse</th>\n",
       "      <td>138.988203</td>\n",
       "      <td>552.791487</td>\n",
       "      <td>135.940109</td>\n",
       "      <td>1554.826630</td>\n",
       "      <td>36130.775816</td>\n",
       "      <td>6159.190611</td>\n",
       "      <td>56.103192</td>\n",
       "      <td>50.665884</td>\n",
       "      <td>2.235548e+07</td>\n",
       "      <td>24.625936</td>\n",
       "      <td>139.781715</td>\n",
       "      <td>30.824116</td>\n",
       "      <td>31.411138</td>\n",
       "      <td>30.021256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_distance</th>\n",
       "      <td>8.712924</td>\n",
       "      <td>19.762664</td>\n",
       "      <td>8.679669</td>\n",
       "      <td>33.495670</td>\n",
       "      <td>161.781433</td>\n",
       "      <td>65.080863</td>\n",
       "      <td>2.838646</td>\n",
       "      <td>3.883170</td>\n",
       "      <td>3.877946e+03</td>\n",
       "      <td>2.102961</td>\n",
       "      <td>9.051113</td>\n",
       "      <td>2.820122</td>\n",
       "      <td>2.591528</td>\n",
       "      <td>2.797981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.991028</td>\n",
       "      <td>0.964329</td>\n",
       "      <td>0.991226</td>\n",
       "      <td>0.899752</td>\n",
       "      <td>-1.342505</td>\n",
       "      <td>0.602990</td>\n",
       "      <td>0.996383</td>\n",
       "      <td>0.996740</td>\n",
       "      <td>-1.441417e+03</td>\n",
       "      <td>0.998411</td>\n",
       "      <td>0.990982</td>\n",
       "      <td>0.998014</td>\n",
       "      <td>0.997974</td>\n",
       "      <td>0.998066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LinearRegression       Lasso       Ridge   ElasticNet  \\\n",
       "fit_time               2.531144    1.054282    0.848534     0.898072   \n",
       "score_time             0.085233    0.081150    0.084967     0.084130   \n",
       "test_mae               8.540289   19.371092    8.507692    32.831996   \n",
       "test_mse             138.988203  552.791487  135.940109  1554.826630   \n",
       "test_distance          8.712924   19.762664    8.679669    33.495670   \n",
       "test_r2                0.991028    0.964329    0.991226     0.899752   \n",
       "\n",
       "               PassiveAggressiveRegressor          SVR  DecisionTreeRegressor  \\\n",
       "fit_time                         0.783983   348.231184               1.469077   \n",
       "score_time                       0.081812   154.376145               0.082450   \n",
       "test_mae                       158.575941    63.791369               2.782402   \n",
       "test_mse                     36130.775816  6159.190611              56.103192   \n",
       "test_distance                  161.781433    65.080863               2.838646   \n",
       "test_r2                         -1.342505     0.602990               0.996383   \n",
       "\n",
       "               KNeighborsRegressor  GaussianProcessRegressor  \\\n",
       "fit_time                  1.982650              3.064316e+02   \n",
       "score_time               31.751880              9.619912e+01   \n",
       "test_mae                  3.806230              3.801109e+03   \n",
       "test_mse                 50.665884              2.235548e+07   \n",
       "test_distance             3.883170              3.877946e+03   \n",
       "test_r2                   0.996740             -1.441417e+03   \n",
       "\n",
       "               AdaBoostRegressor  GradientBoostingRegressor  \\\n",
       "fit_time               83.009644                  38.564748   \n",
       "score_time              0.443865                   0.166302   \n",
       "test_mae                2.061294                   8.871777   \n",
       "test_mse               24.625936                 139.781715   \n",
       "test_distance           2.102961                   9.051113   \n",
       "test_r2                 0.998411                   0.990982   \n",
       "\n",
       "               RandomForestRegressor  ExtraTreesRegressor  BaggingRegressor  \n",
       "fit_time                    8.239344             9.545212          9.469980  \n",
       "score_time                  0.121974             0.135257          0.342275  \n",
       "test_mae                    2.764245             2.540180          2.742543  \n",
       "test_mse                   30.824116            31.411138         30.021256  \n",
       "test_distance               2.820122             2.591528          2.797981  \n",
       "test_r2                     0.998014             0.997974          0.998066  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ===\n",
    "'mae': make_scorer(mae),# 'mean_absolute_error',\n",
    "'mse': make_scorer(mse),#'mean_squared_error',\n",
    "'distance': make_scorer(distance2d),\n",
    "'r2': 'r2'\n",
    "# ===\n",
    "'nbaccuracy' : make_scorer(accert),\n",
    "'accuracy': 'accuracy'\n",
    "# ===   \n",
    "\"\"\"\n",
    "dfLongitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RandomizedSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "hypSwitcher = HyperparameterSwitcher()\n",
    "process = 'randomized'\n",
    "n_iteraciones = 2\n",
    "idModeloPrueba = 7\n",
    "\n",
    "result = {}\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "    \n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "random_search = RandomizedSearchCV(estimador, param_distributions=parametros, \n",
    "                                   n_iter=n_iteraciones, cv=kf, scoring=\"accuracy\", \n",
    "                                   return_train_score=False, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train.FLOOR)\n",
    "result[modelName] = random_search.cv_results_\n",
    "\n",
    "df1 = pd.DataFrame(np.array([result[modelName]['mean_test_score'], result[modelName]['std_test_score'],\n",
    "                             result[modelName]['mean_fit_time'], result[modelName]['std_fit_time'],\n",
    "                             result[modelName]['mean_score_time'], result[modelName]['std_score_time']\n",
    "                            ]).T, columns = ['Accuracy', 'stdAccuracy', 'FitTime', 'stdFitTime', 'ScoreTime', 'stdScoreTime'])\n",
    "df2 = pd.DataFrame(result[modelName]['params'])\n",
    "dff = pd.concat([df1,df2], axis=1).sort_values(['Accuracy', 'FitTime'], ascending=[False, True])\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ExhaustiveSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "process = 'exhaustive'\n",
    "n_iteraciones = 2\n",
    "\n",
    "result = {}\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "    \n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "grid_search = GridSearchCV(estimador, param_grid=parametros, \n",
    "                                   cv=kf, scoring=\"accuracy\", \n",
    "                                   return_train_score=False, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train.FLOOR)\n",
    "result[modelName] = grid_search.cv_results_\n",
    "\n",
    "df1 = pd.DataFrame(np.array([result[modelName]['mean_test_score'], result[modelName]['std_test_score'],\n",
    "                             result[modelName]['mean_fit_time'], result[modelName]['std_fit_time'],\n",
    "                             result[modelName]['mean_score_time'], result[modelName]['std_score_time']\n",
    "                            ]).T, columns = ['Accuracy', 'stdAccuracy', 'FitTime', 'stdFitTime', 'ScoreTime', 'stdScoreTime'])\n",
    "df2 = pd.DataFrame(result[modelName]['params'])\n",
    "dff = pd.concat([df1,df2], axis=1).sort_values(['Accuracy', 'FitTime'], ascending=[False, True])\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EdasSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indice\tAccuracy class_weight criterion\n",
      "0\t0.962077         None   entropy\n",
      "1\t0.955255         None      gini\n",
      "2\t0.962077         None   entropy\n"
     ]
    }
   ],
   "source": [
    "idModeloPrueba = 7\n",
    "#hypSwitcher = HyperparameterSwitcher()\n",
    "process = 'edas'\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "\n",
    "gm = GeneralMethods(estimador, X_train, y_train.FLOOR, seed=seed) ## manage drop duplicates in sample generation\n",
    "test = EdasHyperparameterSearch(\n",
    "    gm, parametros, estimador, iterations=2, sample_size=2, select_ratio=0.5, debug=True) # sample_size*select_ratio>=1\n",
    "test.run()\n",
    "dff = pd.DataFrame(list(test.resultados)).sort_values(['Accuracy'], ascending=False).reset_index(drop=True)\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EasSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos: [1, 1], rangos: [1, 1]\n",
      "--- Evolve in 4 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd       \n",
      "0  \t3     \t0.959967\t0.958082\t0.962077\t0.00163875\n",
      "1  \t2     \t0.960746\t0.958082\t0.962077\t0.0018833 \n",
      "2  \t2     \t0.962077\t0.962077\t0.962077\t1.11022e-16\n",
      "Best individual is: {'criterion': 'entropy', 'class_weight': None}\n",
      "with fitness: 0.9620774431468961\n"
     ]
    }
   ],
   "source": [
    "from lib.easSearch import GeneticSearchCV\n",
    "idModeloPrueba = 7\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "hypSwitcher = HyperparameterSwitcher()\n",
    "process = 'eas'\n",
    "\n",
    "idModeloPrueba = 7\n",
    "result = {}\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "\n",
    "gs2 = GeneticSearchCV(estimador, parametros, cv=kf, n_jobs=4, verbose=1, scoring='accuracy', refit=False\n",
    "                     , generations_number=2, population_size=3)\n",
    "result = gs2.fit(X_train, y_train.FLOOR)\n",
    "dff = pd.DataFrame(list(gs2.result_cache)).sort_values(['Accuracy'], ascending=False).reset_index(drop=True)\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy',\n",
       "  'class_weight': None,\n",
       "  'Accuracy': 0.9620774431468961,\n",
       "  'stdAccuracy': 0.005414661214317645,\n",
       "  'Runtime': 2.373400092124939},\n",
       " {'criterion': 'gini',\n",
       "  'class_weight': 'balanced',\n",
       "  'Accuracy': 0.9597418561770128,\n",
       "  'stdAccuracy': 0.0066779850547021204,\n",
       "  'Runtime': 2.697361779212952},\n",
       " {'criterion': 'gini',\n",
       "  'class_weight': None,\n",
       "  'Accuracy': 0.9552550706822374,\n",
       "  'stdAccuracy': 0.0030706812530539177,\n",
       "  'Runtime': 2.5444828271865845},\n",
       " {'criterion': 'gini',\n",
       "  'class_weight': None,\n",
       "  'Accuracy': 0.9552550706822374,\n",
       "  'stdAccuracy': 0.0030706812530539177,\n",
       "  'Runtime': 2.5315757513046266}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbTest.graphicMap3D(columns = [\"LATITUDE\", \"LONGITUDE\", \"FLOOR\"], filename=\"buildingsMap3dTest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics as scoreMetrics\n",
    "import geopy.distance\n",
    "from functools import reduce\n",
    "#from sklearn.metrics import roc_auc_score # binary\n",
    "#from sklearn.metrics import auc # binary\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "modelClassifier = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "modelRegressor = RandomForestRegressor(n_jobs=-1, random_state=seed)\n",
    "\n",
    "\n",
    "_meanLat = 39.9926853\n",
    "_meanLon = -0.0673033\n",
    "_minLongitude = -7705\n",
    "_maxLongitude = -7290\n",
    "_minLatitude = 4864735\n",
    "_maxLatitude = 4865023\n",
    "_maxLatitudeGPS = 39.993720\n",
    "_maxLongitudeGPS = -0.069254\n",
    "_minLatitudeGPS = 39.991626\n",
    "_minLongitudeGPS = -0.065425\n",
    "\n",
    "def longitudeToGPS(x):\n",
    "    return (_maxLongitudeGPS - _minLongitudeGPS) * (x - _minLongitude) / (_maxLongitude - _minLongitude) + _minLongitudeGPS\n",
    "\n",
    "def latitudeToGPS(x):\n",
    "    return (_maxLatitudeGPS - _minLatitudeGPS) * (x - _minLatitude) / (_maxLatitude - _minLatitude) + _minLatitudeGPS\n",
    "\n",
    "def latitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "\n",
    "def longitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "    \n",
    "def distance2d(y_true, y_pred):\n",
    "    ldis = []\n",
    "    if ((y_true>0).sum()>0):\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "        ldis = latitudeListDistance(y_true, y_pred)\n",
    "    else:\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "        ldis = longitudeListDistance(y_true, y_pred)\n",
    "    return reduce(lambda x,y: x+y, ldis) / len(ldis)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return scoreMetrics.mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "def mae(y_true, y_pred):\n",
    "    return scoreMetrics.mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "scoring_reg = {\n",
    "    'mae': make_scorer(mae),# 'mean_absolute_error',\n",
    "    'mse': make_scorer(mse),#'mean_squared_error',\n",
    "    'distance': make_scorer(distance2d),\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "def accert(y_true, y_pred): \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return (cm.diagonal()/cm.sum(0)).mean()\n",
    "\n",
    "scoring_acc = {\n",
    "    #'average_precision' : 'average_precision_weighted',\n",
    "    #'precision': 'precision',\n",
    "    #'recall': 'recall',\n",
    "    #'balanced_accuracy': 'balanced_accuracy',\n",
    "    #'roc_auc': 'roc_auc',\n",
    "    'nbaccuracy' : make_scorer(accert),\n",
    "    'accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "\n",
    "## TODO: Add and modify some metrics\n",
    "## http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "## https://www.icmla-conference.org/icmla10/CFP_Tutorial_files/jose.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
