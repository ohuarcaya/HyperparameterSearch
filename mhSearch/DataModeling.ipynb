{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./lib/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lib.Methods import GeneralMethods\n",
    "from lib.edasSearch import EdasHyperparameterSearch\n",
    "from lib.Hiperparametros import HyperparameterSwitcher\n",
    "from lib.ImportacionModelos import getClassifierNames\n",
    "from lib.ImportacionModelos import getClassifierModels\n",
    "from lib.ImportacionModelos import getRegressorNames\n",
    "from lib.ImportacionModelos import getRegressorModels\n",
    "from lib.graphicGenerator import GraphicBuilder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Distribución de data 80% data para entrenamiento y 20% para validación__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "seed = 9\n",
    "xSize = 1041\n",
    "kf = KFold(n_splits=10)\n",
    "df = pd.read_csv(\"data/filtred.csv\")\n",
    "X = df[df.columns[:xSize]]\n",
    "Y = df[df.columns[xSize:]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "gbTrain = GraphicBuilder(pd.concat([X_train, y_train],axis=1))\n",
    "gbTest = GraphicBuilder(pd.concat([X_test, y_test],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RandomizedSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "hypSwitcher = HyperparameterSwitcher()\n",
    "process = 'randomized'\n",
    "n_iteraciones = 2\n",
    "idModeloPrueba = 7\n",
    "\n",
    "result = {}\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "    \n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "random_search = RandomizedSearchCV(estimador, param_distributions=parametros, \n",
    "                                   n_iter=n_iteraciones, cv=kf, scoring=\"accuracy\", \n",
    "                                   return_train_score=False, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train.FLOOR)\n",
    "result[modelName] = random_search.cv_results_\n",
    "\n",
    "df1 = pd.DataFrame(np.array([result[modelName]['mean_test_score'], result[modelName]['std_test_score'],\n",
    "                             result[modelName]['mean_fit_time'], result[modelName]['std_fit_time'],\n",
    "                             result[modelName]['mean_score_time'], result[modelName]['std_score_time']\n",
    "                            ]).T, columns = ['Accuracy', 'stdAccuracy', 'FitTime', 'stdFitTime', 'ScoreTime', 'stdScoreTime'])\n",
    "df2 = pd.DataFrame(result[modelName]['params'])\n",
    "dff = pd.concat([df1,df2], axis=1).sort_values(['Accuracy', 'FitTime'], ascending=[False, True])\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ExhaustiveSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "process = 'exhaustive'\n",
    "n_iteraciones = 2\n",
    "\n",
    "result = {}\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "    \n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "grid_search = GridSearchCV(estimador, param_grid=parametros, \n",
    "                                   cv=kf, scoring=\"accuracy\", \n",
    "                                   return_train_score=False, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train.FLOOR)\n",
    "result[modelName] = grid_search.cv_results_\n",
    "\n",
    "df1 = pd.DataFrame(np.array([result[modelName]['mean_test_score'], result[modelName]['std_test_score'],\n",
    "                             result[modelName]['mean_fit_time'], result[modelName]['std_fit_time'],\n",
    "                             result[modelName]['mean_score_time'], result[modelName]['std_score_time']\n",
    "                            ]).T, columns = ['Accuracy', 'stdAccuracy', 'FitTime', 'stdFitTime', 'ScoreTime', 'stdScoreTime'])\n",
    "df2 = pd.DataFrame(result[modelName]['params'])\n",
    "dff = pd.concat([df1,df2], axis=1).sort_values(['Accuracy', 'FitTime'], ascending=[False, True])\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EdasSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indice\tAccuracy class_weight criterion\n",
      "0\t0.962077         None   entropy\n",
      "1\t0.955255         None      gini\n",
      "2\t0.962077         None   entropy\n"
     ]
    }
   ],
   "source": [
    "idModeloPrueba = 7\n",
    "#hypSwitcher = HyperparameterSwitcher()\n",
    "process = 'edas'\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "\n",
    "gm = GeneralMethods(estimador, X_train, y_train.FLOOR, seed=seed) ## manage drop duplicates in sample generation\n",
    "test = EdasHyperparameterSearch(\n",
    "    gm, parametros, estimador, iterations=2, sample_size=2, select_ratio=0.5, debug=True) # sample_size*select_ratio>=1\n",
    "test.run()\n",
    "dff = pd.DataFrame(list(test.resultados)).sort_values(['Accuracy'], ascending=False).reset_index(drop=True)\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EasSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos: [1, 1], rangos: [1, 1]\n",
      "--- Evolve in 4 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd       \n",
      "0  \t3     \t0.959967\t0.958082\t0.962077\t0.00163875\n",
      "1  \t2     \t0.960746\t0.958082\t0.962077\t0.0018833 \n",
      "2  \t2     \t0.962077\t0.962077\t0.962077\t1.11022e-16\n",
      "Best individual is: {'criterion': 'entropy', 'class_weight': None}\n",
      "with fitness: 0.9620774431468961\n"
     ]
    }
   ],
   "source": [
    "from lib.easSearch import GeneticSearchCV\n",
    "idModeloPrueba = 7\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "hypSwitcher = HyperparameterSwitcher()\n",
    "process = 'eas'\n",
    "\n",
    "idModeloPrueba = 7\n",
    "result = {}\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "\n",
    "gs2 = GeneticSearchCV(estimador, parametros, cv=kf, n_jobs=4, verbose=1, scoring='accuracy', refit=False\n",
    "                     , generations_number=2, population_size=3)\n",
    "result = gs2.fit(X_train, y_train.FLOOR)\n",
    "dff = pd.DataFrame(list(gs2.result_cache)).sort_values(['Accuracy'], ascending=False).reset_index(drop=True)\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy',\n",
       "  'class_weight': None,\n",
       "  'Accuracy': 0.9620774431468961,\n",
       "  'stdAccuracy': 0.005414661214317645,\n",
       "  'Runtime': 2.373400092124939},\n",
       " {'criterion': 'gini',\n",
       "  'class_weight': 'balanced',\n",
       "  'Accuracy': 0.9597418561770128,\n",
       "  'stdAccuracy': 0.0066779850547021204,\n",
       "  'Runtime': 2.697361779212952},\n",
       " {'criterion': 'gini',\n",
       "  'class_weight': None,\n",
       "  'Accuracy': 0.9552550706822374,\n",
       "  'stdAccuracy': 0.0030706812530539177,\n",
       "  'Runtime': 2.5444828271865845},\n",
       " {'criterion': 'gini',\n",
       "  'class_weight': None,\n",
       "  'Accuracy': 0.9552550706822374,\n",
       "  'stdAccuracy': 0.0030706812530539177,\n",
       "  'Runtime': 2.5315757513046266}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbTest.graphicMap3D(columns = [\"LATITUDE\", \"LONGITUDE\", \"FLOOR\"], filename=\"buildingsMap3dTest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics as scoreMetrics\n",
    "import geopy.distance\n",
    "from functools import reduce\n",
    "#from sklearn.metrics import roc_auc_score # binary\n",
    "#from sklearn.metrics import auc # binary\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "modelClassifier = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "modelRegressor = RandomForestRegressor(n_jobs=-1, random_state=seed)\n",
    "\n",
    "def accert(y_true, y_pred): \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return (cm.diagonal()/cm.sum(0)).mean()\n",
    "\n",
    "_meanLat = 39.9926853\n",
    "_meanLon = -0.0673033\n",
    "_minLongitude = -7705\n",
    "_maxLongitude = -7290\n",
    "_minLatitude = 4864735\n",
    "_maxLatitude = 4865023\n",
    "_maxLatitudeGPS = 39.993720\n",
    "_maxLongitudeGPS = -0.069254\n",
    "_minLatitudeGPS = 39.991626\n",
    "_minLongitudeGPS = -0.065425\n",
    "\n",
    "def longitudeToGPS(x):\n",
    "    return (_maxLongitudeGPS - _minLongitudeGPS) * (x - _minLongitude) / (_maxLongitude - _minLongitude) + _minLongitudeGPS\n",
    "\n",
    "def latitudeToGPS(x):\n",
    "    return (_maxLatitudeGPS - _minLatitudeGPS) * (x - _minLatitude) / (_maxLatitude - _minLatitude) + _minLatitudeGPS\n",
    "\n",
    "def latitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "\n",
    "def longitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "    \n",
    "def distance2d(y_true, y_pred):\n",
    "    ldis = []\n",
    "    if ((y_true>0).sum()>0):\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "        ldis = latitudeListDistance(y_true, y_pred)\n",
    "    else:\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "        ldis = longitudeListDistance(y_true, y_pred)\n",
    "    return reduce(lambda x,y: x+y, ldis) / len(ldis)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return scoreMetrics.mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "def mae(y_true, y_pred):\n",
    "    return scoreMetrics.mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "scoring_acc = {\n",
    "    #'average_precision' : 'average_precision_weighted',\n",
    "    #'precision': 'precision',\n",
    "    #'recall': 'recall',\n",
    "    #'balanced_accuracy': 'balanced_accuracy',\n",
    "    #'roc_auc': 'roc_auc',\n",
    "    'nbaccuracy' : make_scorer(accert),\n",
    "    'accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "scoring_reg = {\n",
    "    'mae': make_scorer(mae),# 'mean_absolute_error',\n",
    "    'mse': make_scorer(mse),#'mean_squared_error',\n",
    "    'distance': make_scorer(distance2d),\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "## TODO: Add and modify some metrics\n",
    "## http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "## https://www.icmla-conference.org/icmla10/CFP_Tutorial_files/jose.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
