{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time        0.32818429470062255 +/- 0.04760400573155117\n",
       "score_time    0.013472676277160645 +/- 0.003568309638817945\n",
       "test_mae           89996.15594150961 +/- 130219.04564148556\n",
       "test_mse           50182173917689.72 +/- 120859445981983.53\n",
       "test_r2           -72293313736980.64 +/- 174112222814112.25\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time      0.27582075595855715 +/- 0.008178107775353525\n",
       "score_time    0.012851715087890625 +/- 0.00144373510453069\n",
       "test_mae           85089.94062445458 +/- 127147.8782194712\n",
       "test_mse          62943139816736.89 +/- 171696184842814.25\n",
       "test_r2           -90676983460813.39 +/- 247348514208326.1\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time              0.393526029586792 +/- 0.04435700880176216\n",
       "score_time      0.004812550544738769 +/- 5.6144529679850805e-05\n",
       "test_mae               25054195071.745655 +/- 22312965052.83703\n",
       "test_mse        8.774627572845523e+23 +/- 9.725739768424016e+23\n",
       "test_r2       -1.2640881303575365e+24 +/- 1.4011070097444798...\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time            0.40135142803192136 +/- 0.02450366538910096\n",
       "score_time       0.005463814735412598 +/- 0.0013138840883400386\n",
       "test_mae              39703681649.503044 +/- 47188199814.019424\n",
       "test_mse      2.4123455799089627e+24 +/- 4.7506878187679806e+24\n",
       "test_r2       -3.4752670567128053e+24 +/- 6.843923611439712e+24\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time            0.38530113697052004 +/- 0.03090588967060711\n",
       "score_time       0.004860925674438477 +/- 0.0002351358384326568\n",
       "test_mae                   5287487.811167 +/- 4331192.398147694\n",
       "test_mse      2.4542314656948216e+16 +/- 2.3220886580008628e+16\n",
       "test_r2         -3.535608593275871e+16 +/- 3.34524136306432e+16\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time          0.4218210935592651 +/- 0.03143776730104532\n",
       "score_time    0.005525732040405273 +/- 0.0016193906762142043\n",
       "test_mae            71714.94019159491 +/- 188714.88522986489\n",
       "test_mse            25166999120397.688 +/- 76693698835336.06\n",
       "test_r2            -36256017250536.91 +/- 110486278267790.69\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time            0.42221221923828123 +/- 0.05131153768803283\n",
       "score_time      0.005055356025695801 +/- 0.00036873005594932157\n",
       "test_mae               261206633.91949677 +/- 323014749.0456155\n",
       "test_mse       1.4406000138514101e+20 +/- 2.476592518474874e+20\n",
       "test_r2       -2.0753534699728844e+20 +/- 3.567822315359117e+20\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fit_time           0.39957308769226074 +/- 0.011466736511284614\n",
       "score_time       0.005256485939025879 +/- 0.0008528120118625178\n",
       "test_mae               705105055.0242938 +/- 1039987612.5173811\n",
       "test_mse       1.1464326202537182e+21 +/- 1.914064018026102e+21\n",
       "test_r2       -1.6515707994287629e+21 +/- 2.757433960409804e+21\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./lib/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lib.Methods import GeneralMethods\n",
    "from lib.edasSearch import EdasHyperparameterSearch\n",
    "from lib.Hiperparametros import HyperparameterSwitcher\n",
    "from lib.ImportacionModelos import getClassifierNames\n",
    "from lib.ImportacionModelos import getClassifierModels\n",
    "from lib.ImportacionModelos import getRegressorNames\n",
    "from lib.ImportacionModelos import getRegressorModels\n",
    "from lib.graphicGenerator import GraphicBuilder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics as scoreMetrics\n",
    "# import geopy.distance\n",
    "from functools import reduce\n",
    "\n",
    "def accert(y_true, y_pred): \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return (cm.diagonal()/cm.sum(0)).mean()\n",
    "\"\"\"\n",
    "\n",
    "_meanLat = 39.9926853\n",
    "_meanLon = -0.0673033\n",
    "_minLongitude = -7705\n",
    "_maxLongitude = -7290\n",
    "_minLatitude = 4864735\n",
    "_maxLatitude = 4865023\n",
    "_maxLatitudeGPS = 39.993720\n",
    "_maxLongitudeGPS = -0.069254\n",
    "_minLatitudeGPS = 39.991626\n",
    "_minLongitudeGPS = -0.065425\n",
    "\n",
    "def longitudeToGPS(x):\n",
    "    return (_maxLongitudeGPS - _minLongitudeGPS) * (x - _minLongitude) / (_maxLongitude - _minLongitude) + _minLongitudeGPS\n",
    "\n",
    "def latitudeToGPS(x):\n",
    "    return (_maxLatitudeGPS - _minLatitudeGPS) * (x - _minLatitude) / (_maxLatitude - _minLatitude) + _minLatitudeGPS\n",
    "\n",
    "def latitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "\n",
    "def longitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))    \n",
    "\n",
    "def distance2d(y_true, y_pred):\n",
    "    ldis = []\n",
    "    if ((y_true>0).sum()>0):\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "        ldis = latitudeListDistance(y_true, y_pred)\n",
    "    else:\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "        ldis = longitudeListDistance(y_true, y_pred)\n",
    "    return reduce(lambda x,y: x+y, ldis) / len(ldis)\n",
    "\"\"\"\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return scoreMetrics.mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "def mae(y_true, y_pred):\n",
    "    return scoreMetrics.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def score_metrics(estimator, binary=False, params = {}):\n",
    "    score_ = {}\n",
    "    if (is_classifier(estimator)):\n",
    "        if (binary):\n",
    "            score_['average_precision'] = 'average_precision_weighted'\n",
    "            score_['precision'] = 'precision'\n",
    "            score_['recall'] = 'recall'\n",
    "            score_['balanced_accuracy'] = 'balanced_accuracy'\n",
    "            score_['roc_auc'] = 'roc_auc'\n",
    "        score_['nbaccuracy'] = make_scorer(accert)\n",
    "        score_['accuracy'] = 'accuracy'\n",
    "    else:\n",
    "        score_['mae'] = make_scorer(mae) # 'mean_absolute_error',\n",
    "        score_['mse'] = make_scorer(mse) # 'mean_squared_error',\n",
    "        # score['distance'] = make_scorer(distance2d)\n",
    "        score_['r2'] = 'r2'\n",
    "    return score_\n",
    "\n",
    "def cv_fold(estimator, n_splits=10, test_size=0.2, random_state=7):\n",
    "    if (is_classifier(estimator)):\n",
    "        return ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    else:\n",
    "        return StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def clean_dataframe(df, input_columns, target_column, list_val):\n",
    "    x_train = df_train[input_columns]\n",
    "    y_train = df_train[target_column]\n",
    "    if (list_val[0]):\n",
    "        x_train = x_train.apply(lambda x: 100-x, axis=1)\n",
    "    if (list_val[1]):\n",
    "        x_train = preprocessing.scale(x_train)\n",
    "    if (list_val[2]):\n",
    "        x_train = pd.DataFrame(preprocessing.normalize(x_train), columns=wifi_columns) #preprocessing.normalize(x_train)\n",
    "    return x_train, y_train\n",
    "\n",
    "df_train = pd.read_csv(\"data/UJIndoorLoc_trainingData.csv\")\n",
    "df_test = pd.read_csv(\"data/UJIndoorLoc_validationData.csv\")\n",
    "\n",
    "wifi_columns = df_train.columns[:520]\n",
    "target_column = ['BUILDINGID', 'FLOOR', 'LATITUDE', 'LONGITUDE']\n",
    "building = 0\n",
    "floor = 1\n",
    "latitude = 2\n",
    "longitude = 3\n",
    "seed = 7\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "classifier_model = LogisticRegression()\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "## train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "## test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "estimator = regression_model\n",
    "kf = cv_fold(estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ['BUILDINGID', 'FLOOR', 'LATITUDE', 'LONGITUDE']\n",
    "building = 0\n",
    "floor = 1\n",
    "latitude = 2\n",
    "longitude = 3\n",
    "#output[building]\n",
    "\n",
    "wifi_columns = df_train.columns[:520]\n",
    "#x_train = df_train[wifi_columns]\n",
    "#y_train = df_train[output[building]]\n",
    "x_train, y_train = clean_dataframe(df_train, wifi_columns, target_column[building], [1, 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "WARNING:tensorflow:From /Users/ohuarcaya/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/ohuarcaya/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=tf.nn.relu, input_shape=[input_shape]),\n",
    "        layers.Dense(64, activation=tf.nn.relu),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "model = build_model(len(x_train.keys())) #520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                33344     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 37,569\n",
      "Trainable params: 37,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Mean Abs Error:  1.2198014\n",
      "Testing set Mean Sqr Error:  2.1673474\n"
     ]
    }
   ],
   "source": [
    "loss, mae, mse = model.evaluate(x_train, y_train, verbose=0)\n",
    "\n",
    "print(\"Testing set Mean Abs Error:  \" + str(mae))\n",
    "\n",
    "print(\"Testing set Mean Sqr Error:  \" + str(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [1, 1, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 1],\n",
       " [0, 1, 1],\n",
       " [1, 1, 1]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration = [[i%2, int(i/2)%2, int(i/4)] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wifi_columns = df_train.columns[:520]\n",
    "# Transformation Function\n",
    "df_train[wifi_columns] = df_train[wifi_columns].apply(lambda x: 100-x, axis=1) # change range to [0, ...]\n",
    "\n",
    "\n",
    "# euclidean distance  \n",
    "#    d <- sqrt( sum( (xtest[i,]-xtrain[j,])^2 ) )\n",
    "output = ['BUILDINGID', 'FLOOR', 'LATITUDE', 'LONGITUDE']\n",
    "building = 0\n",
    "floor = 1\n",
    "latitude = 2\n",
    "longitude = 3\n",
    "#output[building]\n",
    "\n",
    "wifi_columns = df_train.columns[:520]\n",
    "x_train = df_train[wifi_columns]\n",
    "y_train = df_train[output[building]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "classifier_model = LogisticRegression()\n",
    "regression_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "modelNameList = getClassifierNames(includeEnsambled=True)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def accert(y_true, y_pred): \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return (cm.diagonal()/cm.sum(0)).mean()\n",
    "\n",
    "scoring_acc = {\n",
    "    #'average_precision' : 'average_precision_weighted',\n",
    "    #'precision': 'precision',\n",
    "    #'recall': 'recall',\n",
    "    #'balanced_accuracy': 'balanced_accuracy',\n",
    "    #'roc_auc': 'roc_auc',\n",
    "    'nbaccuracy' : make_scorer(accert),\n",
    "    'accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "\n",
    "#estimador = classifier_model\n",
    "#modelName = str(estimador).split('(')[0]\n",
    "result_acc = cross_validate(classifier_model, x_train, y_train, scoring=scoring_acc, cv=kf, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.275247</td>\n",
       "      <td>0.268692</td>\n",
       "      <td>0.311988</td>\n",
       "      <td>0.240143</td>\n",
       "      <td>0.343994</td>\n",
       "      <td>0.267918</td>\n",
       "      <td>0.234304</td>\n",
       "      <td>0.290608</td>\n",
       "      <td>0.244015</td>\n",
       "      <td>0.224418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.007994</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.005446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_nbaccuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998801</td>\n",
       "      <td>0.983828</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.987462</td>\n",
       "      <td>0.999498</td>\n",
       "      <td>0.984453</td>\n",
       "      <td>0.998997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5  \\\n",
       "fit_time         0.275247  0.268692  0.311988  0.240143  0.343994  0.267918   \n",
       "score_time       0.007994  0.009181  0.006175  0.012188  0.005842  0.005437   \n",
       "test_nbaccuracy       NaN  0.998801  0.983828  0.999072  1.000000  1.000000   \n",
       "test_accuracy    0.987462  0.999498  0.984453  0.998997  1.000000  1.000000   \n",
       "\n",
       "                        6         7         8         9  \n",
       "fit_time         0.234304  0.290608  0.244015  0.224418  \n",
       "score_time       0.010417  0.005345  0.005376  0.005446  \n",
       "test_nbaccuracy  1.000000  0.999008  1.000000  0.997393  \n",
       "test_accuracy    1.000000  0.998495  1.000000  0.995986  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result_acc['test_accuracy'].mean()\n",
    "pd.DataFrame(result_acc).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as scoreMetrics\n",
    "import geopy.distance\n",
    "from functools import reduce\n",
    "\n",
    "#x_trainReg = pd.concat([X_train, y_train[['BUILDINGID']]], axis=1) # , 'FLOOR'\n",
    "\n",
    "_meanLat = 39.9926853\n",
    "_meanLon = -0.0673033\n",
    "_minLongitude = -7705\n",
    "_maxLongitude = -7290\n",
    "_minLatitude = 4864735\n",
    "_maxLatitude = 4865023\n",
    "_maxLatitudeGPS = 39.993720\n",
    "_maxLongitudeGPS = -0.069254\n",
    "_minLatitudeGPS = 39.991626\n",
    "_minLongitudeGPS = -0.065425\n",
    "\n",
    "def longitudeToGPS(x):\n",
    "    return (_maxLongitudeGPS - _minLongitudeGPS) * (x - _minLongitude) / (_maxLongitude - _minLongitude) + _minLongitudeGPS\n",
    "\n",
    "def latitudeToGPS(x):\n",
    "    return (_maxLatitudeGPS - _minLatitudeGPS) * (x - _minLatitude) / (_maxLatitude - _minLatitude) + _minLatitudeGPS\n",
    "\n",
    "def latitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "\n",
    "def longitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "    \n",
    "def distance2d(y_true, y_pred):\n",
    "    ldis = []\n",
    "    if ((y_true>0).sum()>0):\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "        ldis = latitudeListDistance(y_true, y_pred)\n",
    "    else:\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "        ldis = longitudeListDistance(y_true, y_pred)\n",
    "    return reduce(lambda x,y: x+y, ldis) / len(ldis)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return scoreMetrics.mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "def mae(y_true, y_pred):\n",
    "    return scoreMetrics.mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "scoring_reg = {\n",
    "    'mae': make_scorer(mae),# 'mean_absolute_error',\n",
    "    'mse': make_scorer(mse),#'mean_squared_error',\n",
    "    'distance': make_scorer(distance2d),\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "result = cross_validate(RandomForestRegressor(), x_train, df_train[output[latitude]], scoring=scoring_reg, cv=kf, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132.70542971354755"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['test_mse'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import is_classifier\n",
    "is_classifier(regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>3.310302</td>\n",
       "      <td>3.276414</td>\n",
       "      <td>3.206123</td>\n",
       "      <td>3.447507</td>\n",
       "      <td>3.969715</td>\n",
       "      <td>3.946906</td>\n",
       "      <td>3.821521</td>\n",
       "      <td>3.306685</td>\n",
       "      <td>3.727673</td>\n",
       "      <td>3.554831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.060155</td>\n",
       "      <td>0.056511</td>\n",
       "      <td>0.057894</td>\n",
       "      <td>0.068151</td>\n",
       "      <td>0.059055</td>\n",
       "      <td>0.092192</td>\n",
       "      <td>0.056778</td>\n",
       "      <td>0.061817</td>\n",
       "      <td>0.057405</td>\n",
       "      <td>0.062549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mae</th>\n",
       "      <td>11.999786</td>\n",
       "      <td>8.382823</td>\n",
       "      <td>8.553397</td>\n",
       "      <td>4.531076</td>\n",
       "      <td>3.708259</td>\n",
       "      <td>4.153408</td>\n",
       "      <td>7.015856</td>\n",
       "      <td>5.832119</td>\n",
       "      <td>2.504778</td>\n",
       "      <td>5.449663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mse</th>\n",
       "      <td>374.018346</td>\n",
       "      <td>175.070800</td>\n",
       "      <td>312.779440</td>\n",
       "      <td>54.068660</td>\n",
       "      <td>36.673099</td>\n",
       "      <td>46.322053</td>\n",
       "      <td>116.534210</td>\n",
       "      <td>98.546306</td>\n",
       "      <td>30.442981</td>\n",
       "      <td>82.598402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_distance</th>\n",
       "      <td>9.712432</td>\n",
       "      <td>6.784916</td>\n",
       "      <td>6.922975</td>\n",
       "      <td>3.667368</td>\n",
       "      <td>3.001390</td>\n",
       "      <td>3.361689</td>\n",
       "      <td>5.678515</td>\n",
       "      <td>4.720414</td>\n",
       "      <td>2.027314</td>\n",
       "      <td>4.410860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.893941</td>\n",
       "      <td>0.877378</td>\n",
       "      <td>0.852526</td>\n",
       "      <td>0.984421</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.991761</td>\n",
       "      <td>0.939706</td>\n",
       "      <td>0.950103</td>\n",
       "      <td>0.971248</td>\n",
       "      <td>0.980652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0           1           2          3          4  \\\n",
       "fit_time         3.310302    3.276414    3.206123   3.447507   3.969715   \n",
       "score_time       0.060155    0.056511    0.057894   0.068151   0.059055   \n",
       "test_mae        11.999786    8.382823    8.553397   4.531076   3.708259   \n",
       "test_mse       374.018346  175.070800  312.779440  54.068660  36.673099   \n",
       "test_distance    9.712432    6.784916    6.922975   3.667368   3.001390   \n",
       "test_r2          0.893941    0.877378    0.852526   0.984421   0.991170   \n",
       "\n",
       "                       5           6          7          8          9  \n",
       "fit_time        3.946906    3.821521   3.306685   3.727673   3.554831  \n",
       "score_time      0.092192    0.056778   0.061817   0.057405   0.062549  \n",
       "test_mae        4.153408    7.015856   5.832119   2.504778   5.449663  \n",
       "test_mse       46.322053  116.534210  98.546306  30.442981  82.598402  \n",
       "test_distance   3.361689    5.678515   4.720414   2.027314   4.410860  \n",
       "test_r2         0.991761    0.939706   0.950103   0.971248   0.980652  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result).T#.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Distribución de data 80% data para entrenamiento y 20% para validación__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "seed = 9\n",
    "xSize = 1055\n",
    "kf = KFold(n_splits=10)\n",
    "df = pd.read_csv(\"data/filtred.csv\")\n",
    "X = df[df.columns[:xSize]]\n",
    "Y = df[df.columns[xSize:]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "gbTrain = GraphicBuilder(pd.concat([X_train, y_train],axis=1))\n",
    "gbTest = GraphicBuilder(pd.concat([X_test, y_test],axis=1))\n",
    "# x_trainReg = pd.concat([X, Y[['BUILDINGID', 'FLOOR']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_building = []\n",
    "l_floor = []\n",
    "l_latitude = []\n",
    "l_longitude = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>2.272874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.105477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mae</th>\n",
       "      <td>7.024801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mse</th>\n",
       "      <td>89.337374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_distance</th>\n",
       "      <td>5.685750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.980692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LinearRegression\n",
       "fit_time               2.272874\n",
       "score_time             0.105477\n",
       "test_mae               7.024801\n",
       "test_mse              89.337374\n",
       "test_distance          5.685750\n",
       "test_r2                0.980692"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.DataFrame(scoreLat).mean(), columns=[modelName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogisticRegression',\n",
       " 'SGDClassifier',\n",
       " 'PassiveAggressiveClassifier',\n",
       " 'MLPClassifier',\n",
       " 'LinearDiscriminantAnalysis',\n",
       " 'QuadraticDiscriminantAnalysis',\n",
       " 'KNeighborsClassifier',\n",
       " 'DecisionTreeClassifier',\n",
       " 'GaussianNB',\n",
       " 'BernoulliNB',\n",
       " 'MultinomialNB',\n",
       " 'SVC',\n",
       " 'AdaBoostClassifier',\n",
       " 'GradientBoostingClassifier',\n",
       " 'RandomForestClassifier',\n",
       " 'ExtraTreesClassifier',\n",
       " 'VotingClassifier',\n",
       " 'BaggingClassifier']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getClassifierNames(includeEnsambled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLatitude = pd.DataFrame(pd.DataFrame(l_latitude[0]).mean(), columns=['LinearRegression'])\n",
    "dfLatitude['Lasso'] = pd.DataFrame(pd.DataFrame(l_latitude[1]).mean())\n",
    "dfLatitude['Ridge'] = pd.DataFrame(pd.DataFrame(l_latitude[2]).mean())\n",
    "dfLatitude['ElasticNet'] = pd.DataFrame(pd.DataFrame(l_latitude[3]).mean())\n",
    "dfLatitude['PassiveAggressiveRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[4]).mean())\n",
    "dfLatitude['SVR'] = pd.DataFrame(pd.DataFrame(l_latitude[5]).mean())\n",
    "dfLatitude['DecisionTreeRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[6]).mean())\n",
    "dfLatitude['KNeighborsRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[7]).mean())\n",
    "dfLatitude['GaussianProcessRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[8]).mean())\n",
    "dfLatitude['AdaBoostRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[9]).mean())\n",
    "dfLatitude['GradientBoostingRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[10]).mean())\n",
    "dfLatitude['RandomForestRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[11]).mean())\n",
    "dfLatitude['ExtraTreesRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[12]).mean())\n",
    "dfLatitude['BaggingRegressor'] = pd.DataFrame(pd.DataFrame(l_latitude[13]).mean())\n",
    "dfLatitude.to_csv(\"result/_latitude/Comparacion.csv\", index=False)\n",
    "\n",
    "dfLongitude = pd.DataFrame(pd.DataFrame(l_longitude[0]).mean(), columns=['LinearRegression'])\n",
    "dfLongitude['Lasso'] = pd.DataFrame(pd.DataFrame(l_longitude[1]).mean())\n",
    "dfLongitude['Ridge'] = pd.DataFrame(pd.DataFrame(l_longitude[2]).mean())\n",
    "dfLongitude['ElasticNet'] = pd.DataFrame(pd.DataFrame(l_longitude[3]).mean())\n",
    "dfLongitude['PassiveAggressiveRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[4]).mean())\n",
    "dfLongitude['SVR'] = pd.DataFrame(pd.DataFrame(l_longitude[5]).mean())\n",
    "dfLongitude['DecisionTreeRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[6]).mean())\n",
    "dfLongitude['KNeighborsRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[7]).mean())\n",
    "dfLongitude['GaussianProcessRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[8]).mean())\n",
    "dfLongitude['AdaBoostRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[9]).mean())\n",
    "dfLongitude['GradientBoostingRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[10]).mean())\n",
    "dfLongitude['RandomForestRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[11]).mean())\n",
    "dfLongitude['ExtraTreesRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[12]).mean())\n",
    "dfLongitude['BaggingRegressor'] = pd.DataFrame(pd.DataFrame(l_longitude[13]).mean())\n",
    "dfLongitude.to_csv(\"result/_longitude/Comparacion.csv\", index=False)\n",
    "\n",
    "dfFloor = pd.DataFrame(pd.DataFrame(l_floor[0]).mean(), columns=['LogisticRegression'])\n",
    "dfFloor['SGDClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[1]).mean())\n",
    "dfFloor['PassiveAggressiveClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[2]).mean())\n",
    "dfFloor['MLPClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[3]).mean())\n",
    "dfFloor['LinearDiscriminantAnalysis'] = pd.DataFrame(pd.DataFrame(l_floor[4]).mean())\n",
    "dfFloor['QuadraticDiscriminantAnalysis'] = pd.DataFrame(pd.DataFrame(l_floor[5]).mean())\n",
    "dfFloor['KNeighborsClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[6]).mean())\n",
    "dfFloor['DecisionTreeClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[7]).mean())\n",
    "dfFloor['GaussianNB'] = pd.DataFrame(pd.DataFrame(l_floor[8]).mean())\n",
    "dfFloor['BernoulliNB'] = pd.DataFrame(pd.DataFrame(l_floor[9]).mean())\n",
    "dfFloor['MultinomialNB'] = pd.DataFrame(pd.DataFrame(l_floor[10]).mean())\n",
    "dfFloor['SVC'] = pd.DataFrame(pd.DataFrame(l_floor[11]).mean())\n",
    "dfFloor['AdaBoostClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[12]).mean())\n",
    "dfFloor['GradientBoostingClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[13]).mean())\n",
    "dfFloor['RandomForestClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[14]).mean())\n",
    "dfFloor['ExtraTreesClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[15]).mean())\n",
    "dfFloor['VotingClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[16]).mean())\n",
    "dfFloor['BaggingClassifier'] = pd.DataFrame(pd.DataFrame(l_floor[17]).mean())\n",
    "dfFloor.to_csv(\"result/_floor/Comparacion.csv\", index=False)\n",
    "\n",
    "dfBuilding = pd.DataFrame(pd.DataFrame(l_building[0]).mean(), columns=['LogisticRegression'])\n",
    "dfBuilding['SGDClassifier'] = pd.DataFrame(pd.DataFrame(l_building[1]).mean())\n",
    "dfBuilding['PassiveAggressiveClassifier'] = pd.DataFrame(pd.DataFrame(l_building[2]).mean())\n",
    "dfBuilding['MLPClassifier'] = pd.DataFrame(pd.DataFrame(l_building[3]).mean())\n",
    "dfBuilding['LinearDiscriminantAnalysis'] = pd.DataFrame(pd.DataFrame(l_building[4]).mean())\n",
    "dfBuilding['QuadraticDiscriminantAnalysis'] = pd.DataFrame(pd.DataFrame(l_building[5]).mean())\n",
    "dfBuilding['KNeighborsClassifier'] = pd.DataFrame(pd.DataFrame(l_building[6]).mean())\n",
    "dfBuilding['DecisionTreeClassifier'] = pd.DataFrame(pd.DataFrame(l_building[7]).mean())\n",
    "dfBuilding['GaussianNB'] = pd.DataFrame(pd.DataFrame(l_building[8]).mean())\n",
    "dfBuilding['BernoulliNB'] = pd.DataFrame(pd.DataFrame(l_building[9]).mean())\n",
    "dfBuilding['MultinomialNB'] = pd.DataFrame(pd.DataFrame(l_building[10]).mean())\n",
    "dfBuilding['SVC'] = pd.DataFrame(pd.DataFrame(l_building[11]).mean())\n",
    "dfBuilding['AdaBoostClassifier'] = pd.DataFrame(pd.DataFrame(l_building[12]).mean())\n",
    "dfBuilding['GradientBoostingClassifier'] = pd.DataFrame(pd.DataFrame(l_building[13]).mean())\n",
    "dfBuilding['RandomForestClassifier'] = pd.DataFrame(pd.DataFrame(l_building[14]).mean())\n",
    "dfBuilding['ExtraTreesClassifier'] = pd.DataFrame(pd.DataFrame(l_building[15]).mean())\n",
    "dfBuilding['VotingClassifier'] = pd.DataFrame(pd.DataFrame(l_building[16]).mean())\n",
    "dfBuilding['BaggingClassifier'] = pd.DataFrame(pd.DataFrame(l_building[17]).mean())\n",
    "dfBuilding.to_csv(\"result/_building/Comparacion.csv\", index=False)\n",
    "\n",
    "#pd.DataFrame(pd.DataFrame(l_building[0]).mean(), columns=[modelName])\n",
    "#l_floor\n",
    "#l_latitude\n",
    "#l_longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <th>SVR</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <th>BaggingRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>2.531144</td>\n",
       "      <td>1.054282</td>\n",
       "      <td>0.848534</td>\n",
       "      <td>0.898072</td>\n",
       "      <td>0.783983</td>\n",
       "      <td>348.231184</td>\n",
       "      <td>1.469077</td>\n",
       "      <td>1.982650</td>\n",
       "      <td>3.064316e+02</td>\n",
       "      <td>83.009644</td>\n",
       "      <td>38.564748</td>\n",
       "      <td>8.239344</td>\n",
       "      <td>9.545212</td>\n",
       "      <td>9.469980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.085233</td>\n",
       "      <td>0.081150</td>\n",
       "      <td>0.084967</td>\n",
       "      <td>0.084130</td>\n",
       "      <td>0.081812</td>\n",
       "      <td>154.376145</td>\n",
       "      <td>0.082450</td>\n",
       "      <td>31.751880</td>\n",
       "      <td>9.619912e+01</td>\n",
       "      <td>0.443865</td>\n",
       "      <td>0.166302</td>\n",
       "      <td>0.121974</td>\n",
       "      <td>0.135257</td>\n",
       "      <td>0.342275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mae</th>\n",
       "      <td>8.540289</td>\n",
       "      <td>19.371092</td>\n",
       "      <td>8.507692</td>\n",
       "      <td>32.831996</td>\n",
       "      <td>158.575941</td>\n",
       "      <td>63.791369</td>\n",
       "      <td>2.782402</td>\n",
       "      <td>3.806230</td>\n",
       "      <td>3.801109e+03</td>\n",
       "      <td>2.061294</td>\n",
       "      <td>8.871777</td>\n",
       "      <td>2.764245</td>\n",
       "      <td>2.540180</td>\n",
       "      <td>2.742543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mse</th>\n",
       "      <td>138.988203</td>\n",
       "      <td>552.791487</td>\n",
       "      <td>135.940109</td>\n",
       "      <td>1554.826630</td>\n",
       "      <td>36130.775816</td>\n",
       "      <td>6159.190611</td>\n",
       "      <td>56.103192</td>\n",
       "      <td>50.665884</td>\n",
       "      <td>2.235548e+07</td>\n",
       "      <td>24.625936</td>\n",
       "      <td>139.781715</td>\n",
       "      <td>30.824116</td>\n",
       "      <td>31.411138</td>\n",
       "      <td>30.021256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_distance</th>\n",
       "      <td>8.712924</td>\n",
       "      <td>19.762664</td>\n",
       "      <td>8.679669</td>\n",
       "      <td>33.495670</td>\n",
       "      <td>161.781433</td>\n",
       "      <td>65.080863</td>\n",
       "      <td>2.838646</td>\n",
       "      <td>3.883170</td>\n",
       "      <td>3.877946e+03</td>\n",
       "      <td>2.102961</td>\n",
       "      <td>9.051113</td>\n",
       "      <td>2.820122</td>\n",
       "      <td>2.591528</td>\n",
       "      <td>2.797981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.991028</td>\n",
       "      <td>0.964329</td>\n",
       "      <td>0.991226</td>\n",
       "      <td>0.899752</td>\n",
       "      <td>-1.342505</td>\n",
       "      <td>0.602990</td>\n",
       "      <td>0.996383</td>\n",
       "      <td>0.996740</td>\n",
       "      <td>-1.441417e+03</td>\n",
       "      <td>0.998411</td>\n",
       "      <td>0.990982</td>\n",
       "      <td>0.998014</td>\n",
       "      <td>0.997974</td>\n",
       "      <td>0.998066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LinearRegression       Lasso       Ridge   ElasticNet  \\\n",
       "fit_time               2.531144    1.054282    0.848534     0.898072   \n",
       "score_time             0.085233    0.081150    0.084967     0.084130   \n",
       "test_mae               8.540289   19.371092    8.507692    32.831996   \n",
       "test_mse             138.988203  552.791487  135.940109  1554.826630   \n",
       "test_distance          8.712924   19.762664    8.679669    33.495670   \n",
       "test_r2                0.991028    0.964329    0.991226     0.899752   \n",
       "\n",
       "               PassiveAggressiveRegressor          SVR  DecisionTreeRegressor  \\\n",
       "fit_time                         0.783983   348.231184               1.469077   \n",
       "score_time                       0.081812   154.376145               0.082450   \n",
       "test_mae                       158.575941    63.791369               2.782402   \n",
       "test_mse                     36130.775816  6159.190611              56.103192   \n",
       "test_distance                  161.781433    65.080863               2.838646   \n",
       "test_r2                         -1.342505     0.602990               0.996383   \n",
       "\n",
       "               KNeighborsRegressor  GaussianProcessRegressor  \\\n",
       "fit_time                  1.982650              3.064316e+02   \n",
       "score_time               31.751880              9.619912e+01   \n",
       "test_mae                  3.806230              3.801109e+03   \n",
       "test_mse                 50.665884              2.235548e+07   \n",
       "test_distance             3.883170              3.877946e+03   \n",
       "test_r2                   0.996740             -1.441417e+03   \n",
       "\n",
       "               AdaBoostRegressor  GradientBoostingRegressor  \\\n",
       "fit_time               83.009644                  38.564748   \n",
       "score_time              0.443865                   0.166302   \n",
       "test_mae                2.061294                   8.871777   \n",
       "test_mse               24.625936                 139.781715   \n",
       "test_distance           2.102961                   9.051113   \n",
       "test_r2                 0.998411                   0.990982   \n",
       "\n",
       "               RandomForestRegressor  ExtraTreesRegressor  BaggingRegressor  \n",
       "fit_time                    8.239344             9.545212          9.469980  \n",
       "score_time                  0.121974             0.135257          0.342275  \n",
       "test_mae                    2.764245             2.540180          2.742543  \n",
       "test_mse                   30.824116            31.411138         30.021256  \n",
       "test_distance               2.820122             2.591528          2.797981  \n",
       "test_r2                     0.998014             0.997974          0.998066  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ===\n",
    "'mae': make_scorer(mae),# 'mean_absolute_error',\n",
    "'mse': make_scorer(mse),#'mean_squared_error',\n",
    "'distance': make_scorer(distance2d),\n",
    "'r2': 'r2'\n",
    "# ===\n",
    "'nbaccuracy' : make_scorer(accert),\n",
    "'accuracy': 'accuracy'\n",
    "# ===   \n",
    "\"\"\"\n",
    "dfLongitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RandomizedSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "hypSwitcher = HyperparameterSwitcher()\n",
    "process = 'randomized'\n",
    "n_iteraciones = 2\n",
    "idModeloPrueba = 7\n",
    "\n",
    "result = {}\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "    \n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "random_search = RandomizedSearchCV(estimador, param_distributions=parametros, \n",
    "                                   n_iter=n_iteraciones, cv=kf, scoring=\"accuracy\", \n",
    "                                   return_train_score=False, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train.FLOOR)\n",
    "result[modelName] = random_search.cv_results_\n",
    "\n",
    "df1 = pd.DataFrame(np.array([result[modelName]['mean_test_score'], result[modelName]['std_test_score'],\n",
    "                             result[modelName]['mean_fit_time'], result[modelName]['std_fit_time'],\n",
    "                             result[modelName]['mean_score_time'], result[modelName]['std_score_time']\n",
    "                            ]).T, columns = ['Accuracy', 'stdAccuracy', 'FitTime', 'stdFitTime', 'ScoreTime', 'stdScoreTime'])\n",
    "df2 = pd.DataFrame(result[modelName]['params'])\n",
    "dff = pd.concat([df1,df2], axis=1).sort_values(['Accuracy', 'FitTime'], ascending=[False, True])\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ExhaustiveSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "process = 'exhaustive'\n",
    "n_iteraciones = 2\n",
    "\n",
    "result = {}\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "    \n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "grid_search = GridSearchCV(estimador, param_grid=parametros, \n",
    "                                   cv=kf, scoring=\"accuracy\", \n",
    "                                   return_train_score=False, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train.FLOOR)\n",
    "result[modelName] = grid_search.cv_results_\n",
    "\n",
    "df1 = pd.DataFrame(np.array([result[modelName]['mean_test_score'], result[modelName]['std_test_score'],\n",
    "                             result[modelName]['mean_fit_time'], result[modelName]['std_fit_time'],\n",
    "                             result[modelName]['mean_score_time'], result[modelName]['std_score_time']\n",
    "                            ]).T, columns = ['Accuracy', 'stdAccuracy', 'FitTime', 'stdFitTime', 'ScoreTime', 'stdScoreTime'])\n",
    "df2 = pd.DataFrame(result[modelName]['params'])\n",
    "dff = pd.concat([df1,df2], axis=1).sort_values(['Accuracy', 'FitTime'], ascending=[False, True])\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EdasSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indice\tAccuracy class_weight criterion\n",
      "0\t0.962077         None   entropy\n",
      "1\t0.955255         None      gini\n",
      "2\t0.962077         None   entropy\n"
     ]
    }
   ],
   "source": [
    "idModeloPrueba = 7\n",
    "#hypSwitcher = HyperparameterSwitcher()\n",
    "process = 'edas'\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "\n",
    "gm = GeneralMethods(estimador, X_train, y_train.FLOOR, seed=seed) ## manage drop duplicates in sample generation\n",
    "test = EdasHyperparameterSearch(\n",
    "    gm, parametros, estimador, iterations=2, sample_size=2, select_ratio=0.5, debug=True) # sample_size*select_ratio>=1\n",
    "test.run()\n",
    "dff = pd.DataFrame(list(test.resultados)).sort_values(['Accuracy'], ascending=False).reset_index(drop=True)\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EasSearch: Probando con un modelo de Clasificación, los demás se probarán en Servidor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos: [1, 1], rangos: [1, 1]\n",
      "--- Evolve in 4 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd       \n",
      "0  \t3     \t0.959967\t0.958082\t0.962077\t0.00163875\n",
      "1  \t2     \t0.960746\t0.958082\t0.962077\t0.0018833 \n",
      "2  \t2     \t0.962077\t0.962077\t0.962077\t1.11022e-16\n",
      "Best individual is: {'criterion': 'entropy', 'class_weight': None}\n",
      "with fitness: 0.9620774431468961\n"
     ]
    }
   ],
   "source": [
    "from lib.easSearch import GeneticSearchCV\n",
    "idModeloPrueba = 7\n",
    "estimadorDictionary = getClassifierModels(includeEnsambled=True)\n",
    "hypSwitcher = HyperparameterSwitcher()\n",
    "process = 'eas'\n",
    "\n",
    "idModeloPrueba = 7\n",
    "result = {}\n",
    "modelName = getClassifierNames(includeEnsambled=True)[idModeloPrueba]\n",
    "estimador = estimadorDictionary[modelName]\n",
    "parametros = hypSwitcher.getHyperparameters(modelName)(isDummy=False)\n",
    "\n",
    "gs2 = GeneticSearchCV(estimador, parametros, cv=kf, n_jobs=4, verbose=1, scoring='accuracy', refit=False\n",
    "                     , generations_number=2, population_size=3)\n",
    "result = gs2.fit(X_train, y_train.FLOOR)\n",
    "dff = pd.DataFrame(list(gs2.result_cache)).sort_values(['Accuracy'], ascending=False).reset_index(drop=True)\n",
    "dff.to_csv(\"result/\" + process + \"/\" + modelName + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy',\n",
       "  'class_weight': None,\n",
       "  'Accuracy': 0.9620774431468961,\n",
       "  'stdAccuracy': 0.005414661214317645,\n",
       "  'Runtime': 2.373400092124939},\n",
       " {'criterion': 'gini',\n",
       "  'class_weight': 'balanced',\n",
       "  'Accuracy': 0.9597418561770128,\n",
       "  'stdAccuracy': 0.0066779850547021204,\n",
       "  'Runtime': 2.697361779212952},\n",
       " {'criterion': 'gini',\n",
       "  'class_weight': None,\n",
       "  'Accuracy': 0.9552550706822374,\n",
       "  'stdAccuracy': 0.0030706812530539177,\n",
       "  'Runtime': 2.5444828271865845},\n",
       " {'criterion': 'gini',\n",
       "  'class_weight': None,\n",
       "  'Accuracy': 0.9552550706822374,\n",
       "  'stdAccuracy': 0.0030706812530539177,\n",
       "  'Runtime': 2.5315757513046266}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbTest.graphicMap3D(columns = [\"LATITUDE\", \"LONGITUDE\", \"FLOOR\"], filename=\"buildingsMap3dTest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./lib/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lib.Methods import GeneralMethods\n",
    "from lib.edasSearch import EdasHyperparameterSearch\n",
    "from lib.Hiperparametros import HyperparameterSwitcher\n",
    "from lib.ImportacionModelos import getClassifierNames\n",
    "from lib.ImportacionModelos import getClassifierModels\n",
    "from lib.ImportacionModelos import getRegressorNames\n",
    "from lib.ImportacionModelos import getRegressorModels\n",
    "from lib.graphicGenerator import GraphicBuilder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics as scoreMetrics\n",
    "# import geopy.distance\n",
    "from functools import reduce\n",
    "\n",
    "def accert(y_true, y_pred): \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return (cm.diagonal()/cm.sum(0)).mean()\n",
    "\"\"\"\n",
    "\n",
    "_meanLat = 39.9926853\n",
    "_meanLon = -0.0673033\n",
    "_minLongitude = -7705\n",
    "_maxLongitude = -7290\n",
    "_minLatitude = 4864735\n",
    "_maxLatitude = 4865023\n",
    "_maxLatitudeGPS = 39.993720\n",
    "_maxLongitudeGPS = -0.069254\n",
    "_minLatitudeGPS = 39.991626\n",
    "_minLongitudeGPS = -0.065425\n",
    "\n",
    "def longitudeToGPS(x):\n",
    "    return (_maxLongitudeGPS - _minLongitudeGPS) * (x - _minLongitude) / (_maxLongitude - _minLongitude) + _minLongitudeGPS\n",
    "\n",
    "def latitudeToGPS(x):\n",
    "    return (_maxLatitudeGPS - _minLatitudeGPS) * (x - _minLatitude) / (_maxLatitude - _minLatitude) + _minLatitudeGPS\n",
    "\n",
    "def latitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "\n",
    "def longitudeListDistance(y_true, y_pred):\n",
    "    return list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))    \n",
    "\n",
    "def distance2d(y_true, y_pred):\n",
    "    ldis = []\n",
    "    if ((y_true>0).sum()>0):\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((_meanLon, yt),(_meanLon, yp)).m , latitudeToGPS(y_true), latitudeToGPS(y_pred)))\n",
    "        ldis = latitudeListDistance(y_true, y_pred)\n",
    "    else:\n",
    "        #ldis = list(map(lambda yt,yp : geopy.distance.vincenty((yt, _meanLat),(yp, _meanLat)).m , longitudeToGPS(y_true), longitudeToGPS(y_pred)))\n",
    "        ldis = longitudeListDistance(y_true, y_pred)\n",
    "    return reduce(lambda x,y: x+y, ldis) / len(ldis)\n",
    "\"\"\"\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return scoreMetrics.mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "def mae(y_true, y_pred):\n",
    "    return scoreMetrics.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def score_metrics(estimator, binary=False, params = {}):\n",
    "    score_ = {}\n",
    "    if (is_classifier(estimator)):\n",
    "        if (binary):\n",
    "            score_['average_precision'] = 'average_precision_weighted'\n",
    "            score_['precision'] = 'precision'\n",
    "            score_['recall'] = 'recall'\n",
    "            score_['balanced_accuracy'] = 'balanced_accuracy'\n",
    "            score_['roc_auc'] = 'roc_auc'\n",
    "        score_['nbaccuracy'] = make_scorer(accert)\n",
    "        score_['accuracy'] = 'accuracy'\n",
    "    else:\n",
    "        score_['mae'] = make_scorer(mae) # 'mean_absolute_error',\n",
    "        score_['mse'] = make_scorer(mse) # 'mean_squared_error',\n",
    "        # score['distance'] = make_scorer(distance2d)\n",
    "        score_['r2'] = 'r2'\n",
    "    return score_\n",
    "\n",
    "def cv_fold(estimator, n_splits=10, test_size=0.2, random_state=7):\n",
    "    if (is_classifier(estimator)):\n",
    "        return ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    else:\n",
    "        return StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def clean_dataframe(df, input_columns, target_column, list_val):\n",
    "    x_train = df_train[input_columns]\n",
    "    y_train = df_train[target_column]\n",
    "    if (list_val[0]):\n",
    "        x_train = x_train.apply(lambda x: 100-x, axis=1)\n",
    "    if (list_val[1]):\n",
    "        x_train = preprocessing.scale(x_train)\n",
    "    if (list_val[2]):\n",
    "        x_train = preprocessing.normalize(x_train)\n",
    "    return x_train, y_train\n",
    "\n",
    "df_train = pd.read_csv(\"data/UJIndoorLoc_trainingData.csv\")\n",
    "df_test = pd.read_csv(\"data/UJIndoorLoc_validationData.csv\")\n",
    "\n",
    "wifi_columns = df_train.columns[:520]\n",
    "target_column = ['BUILDINGID', 'FLOOR', 'LATITUDE', 'LONGITUDE']\n",
    "building = 0\n",
    "floor = 1\n",
    "latitude = 2\n",
    "longitude = 3\n",
    "seed = 7\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "classifier_model = LogisticRegression()\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "## train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "## test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "estimator = regression_model\n",
    "kf = cv_fold(estimator)\n",
    "\n",
    "result_list = []\n",
    "iteration = [[i%2, int(i/2)%2, int(i/4)] for i in range(8)]\n",
    "\"\"\"\n",
    "for item in iteration:\n",
    "    x, y = clean_dataframe(df_train, wifi_columns, target_column[building], item)\n",
    "    result = cross_validate(estimator, x, y, scoring=score_metrics(estimator), cv=kf, return_train_score=False)\n",
    "    display(pd.DataFrame(result).mean().astype(str) + \" +/- \" + pd.DataFrame(result).std().astype(str))\n",
    "    result_list.append(result)\n",
    "\"\"\"\n",
    "def build_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=tf.nn.relu, input_shape=[input_shape]),\n",
    "        layers.Dense(64, activation=tf.nn.relu),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "    model = build_model(len(x_train.keys())) #520\n",
    "\n",
    "\n",
    "#print(result_list)\n",
    "#pd.DataFrame(result_list).T #.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
