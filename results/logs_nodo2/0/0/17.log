/usr/lib/python3.4/site-packages/deap/tools/_hypervolume/pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.
  "module. Expect this to be very slow.", ImportWarning)
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 344, in __call__
    return self.func(*args, **kwargs)
  File "/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/usr/lib64/python3.4/site-packages/sklearn/model_selection/_validation.py", line 238, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/lib64/python3.4/site-packages/sklearn/ensemble/bagging.py", line 248, in fit
    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)
  File "/usr/lib64/python3.4/site-packages/sklearn/ensemble/bagging.py", line 327, in _fit
    raise ValueError("Out of bag estimate only available"
ValueError: Out of bag estimate only available if warm_start=False

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib64/python3.4/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 353, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
ValueError                                         Tue Dec 11 03:43:22 2018
PID: 3300                                    Python 3.4.9: /usr/bin/python3
...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True),        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], 6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, make_scorer(accuracy_score), array([ 1627,  1628,  1629, ..., 16267, 16268, 16269]), array([   0,    1,    2, ..., 1624, 1625, 1626]), 0, {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 3, 'oob_score': True, 'warm_start': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': False})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True),        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], 6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, make_scorer(accuracy_score), array([ 1627,  1628,  1629, ..., 16267, 16268, 16269]), array([   0,    1,    2, ..., 1624, 1625, 1626]), 0, {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 3, 'oob_score': True, 'warm_start': True})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': False}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True), X=       WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], y=6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, scorer=make_scorer(accuracy_score), train=array([ 1627,  1628,  1629, ..., 16267, 16268, 16269]), test=array([   0,    1,    2, ..., 1624, 1625, 1626]), verbose=0, parameters={'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 3, 'oob_score': True, 'warm_start': True}, fit_params={}, return_train_score=False, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method BaggingClassifier.fit of BaggingCl...     random_state=7, verbose=0, warm_start=True)>
        X_train =        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[14643 rows x 1041 columns]
        y_train = 11757    1
289      3
1946     3
15119    0
1136...1      3
Name: FLOOR, Length: 14643, dtype: int64
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/ensemble/bagging.py in fit(self=BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True), X=       WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[14643 rows x 1041 columns], y=11757    1
289      3
1946     3
15119    0
1136...1      3
Name: FLOOR, Length: 14643, dtype: int64, sample_weight=None)
    243         Returns
    244         -------
    245         self : object
    246             Returns self.
    247         """
--> 248         return self._fit(X, y, self.max_samples, sample_weight=sample_weight)
        self._fit = <bound method BaggingClassifier._fit of BaggingC...     random_state=7, verbose=0, warm_start=True)>
        X =        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[14643 rows x 1041 columns]
        y = 11757    1
289      3
1946     3
15119    0
1136...1      3
Name: FLOOR, Length: 14643, dtype: int64
        self.max_samples = 1.0
        sample_weight = None
    249 
    250     def _fit(self, X, y, max_samples=None, max_depth=None, sample_weight=None):
    251         """Build a Bagging ensemble of estimators from the training
    252            set (X, y).

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/ensemble/bagging.py in _fit(self=BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True), X=array([[  0.,   0.,   0., ...,   1.,   1., 501.]...      [  0.,   0.,   0., ...,   1.,   1., 503.]]), y=array([1, 3, 3, ..., 0, 3, 3]), max_samples=14643, max_depth=None, sample_weight=None)
    322         if not self.bootstrap and self.oob_score:
    323             raise ValueError("Out of bag estimation only available"
    324                              " if bootstrap=True")
    325 
    326         if self.warm_start and self.oob_score:
--> 327             raise ValueError("Out of bag estimate only available"
    328                              " if warm_start=False")
    329 
    330         if hasattr(self, "oob_score_") and self.warm_start:
    331             del self.oob_score_

ValueError: Out of bag estimate only available if warm_start=False
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/usr/lib64/python3.4/multiprocessing/pool.py", line 608, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
ValueError                                         Tue Dec 11 03:43:22 2018
PID: 3300                                    Python 3.4.9: /usr/bin/python3
...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True),        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], 6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, make_scorer(accuracy_score), array([ 1627,  1628,  1629, ..., 16267, 16268, 16269]), array([   0,    1,    2, ..., 1624, 1625, 1626]), 0, {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 3, 'oob_score': True, 'warm_start': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': False})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True),        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], 6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, make_scorer(accuracy_score), array([ 1627,  1628,  1629, ..., 16267, 16268, 16269]), array([   0,    1,    2, ..., 1624, 1625, 1626]), 0, {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 3, 'oob_score': True, 'warm_start': True})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': False}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True), X=       WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], y=6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, scorer=make_scorer(accuracy_score), train=array([ 1627,  1628,  1629, ..., 16267, 16268, 16269]), test=array([   0,    1,    2, ..., 1624, 1625, 1626]), verbose=0, parameters={'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 3, 'oob_score': True, 'warm_start': True}, fit_params={}, return_train_score=False, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method BaggingClassifier.fit of BaggingCl...     random_state=7, verbose=0, warm_start=True)>
        X_train =        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[14643 rows x 1041 columns]
        y_train = 11757    1
289      3
1946     3
15119    0
1136...1      3
Name: FLOOR, Length: 14643, dtype: int64
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/ensemble/bagging.py in fit(self=BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True), X=       WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[14643 rows x 1041 columns], y=11757    1
289      3
1946     3
15119    0
1136...1      3
Name: FLOOR, Length: 14643, dtype: int64, sample_weight=None)
    243         Returns
    244         -------
    245         self : object
    246             Returns self.
    247         """
--> 248         return self._fit(X, y, self.max_samples, sample_weight=sample_weight)
        self._fit = <bound method BaggingClassifier._fit of BaggingC...     random_state=7, verbose=0, warm_start=True)>
        X =        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[14643 rows x 1041 columns]
        y = 11757    1
289      3
1946     3
15119    0
1136...1      3
Name: FLOOR, Length: 14643, dtype: int64
        self.max_samples = 1.0
        sample_weight = None
    249 
    250     def _fit(self, X, y, max_samples=None, max_depth=None, sample_weight=None):
    251         """Build a Bagging ensemble of estimators from the training
    252            set (X, y).

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/ensemble/bagging.py in _fit(self=BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True), X=array([[  0.,   0.,   0., ...,   1.,   1., 501.]...      [  0.,   0.,   0., ...,   1.,   1., 503.]]), y=array([1, 3, 3, ..., 0, 3, 3]), max_samples=14643, max_depth=None, sample_weight=None)
    322         if not self.bootstrap and self.oob_score:
    323             raise ValueError("Out of bag estimation only available"
    324                              " if bootstrap=True")
    325 
    326         if self.warm_start and self.oob_score:
--> 327             raise ValueError("Out of bag estimate only available"
    328                              " if warm_start=False")
    329 
    330         if hasattr(self, "oob_score_") and self.warm_start:
    331             del self.oob_score_

ValueError: Out of bag estimate only available if warm_start=False
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 58, in <module>
    ev.fit(scoring='accuracy', n_jobs=cpu_count(), kargs=searchParams)
  File "/home/Manuel.Castillo/pruebasOHC/lib/ProcessManager.py", line 62, in fit
    rscv.fit(self.X, self.y)
  File "/usr/lib64/python3.4/site-packages/sklearn/model_selection/_search.py", line 1190, in fit
    return self._fit(X, y, groups, sampled_params)
  File "/usr/lib64/python3.4/site-packages/sklearn/model_selection/_search.py", line 564, in _fit
    for parameters in parameter_iterable
  File "/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__
    self.retrieve()
  File "/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibValueError: JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/Manuel.Castillo/pruebasOHC/main.py in <module>()
     53 """
     54 ev = Evaluator(X_train, y_train[y_column])
     55 ev.setEstimador(estimador)
     56 ev.setParams(parametros)
     57 ev.setTypeSearch(process)
---> 58 ev.fit(scoring='accuracy', n_jobs=cpu_count(), kargs=searchParams)
     59 # Guardar Modelo en formato csv
     60 ev.saveDataFrame(modelName + y_column)
     61 
     62 

...........................................................................
/home/Manuel.Castillo/pruebasOHC/lib/ProcessManager.py in fit(self=<lib.ProcessManager.Evaluator object>, scoring='accuracy', n_jobs=16, kargs={'elit': 3, 'ngen': 4, 'pelit': 0.5, 'psize': 10})
     57             self.dff = pd.concat([df1,df2], axis=1).sort_values(['Accuracy', 'FitTime'], ascending=[False, True])
     58         if (self.type == 'randomized'):
     59             rscv = RandomizedSearchCV(self.estimador, param_distributions=self.params, 
     60                                 n_iter=generaciones, cv=self.kf, scoring="accuracy", 
     61                                 return_train_score=False, n_jobs=n_jobs)
---> 62             rscv.fit(self.X, self.y)
        rscv.fit = <bound method RandomizedSearchCV.fit of Randomiz...rain_score=False, scoring='accuracy', verbose=0)>
        self.X =        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns]
        self.y = 6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64
     63             rscv.cv_results_ = rscv.cv_results_
     64             df1 = pd.DataFrame(np.array([rscv.cv_results_['mean_test_score'], rscv.cv_results_['std_test_score'],
     65                                         rscv.cv_results_['mean_fit_time'], rscv.cv_results_['std_fit_time'],
     66                                         rscv.cv_results_['mean_score_time'], rscv.cv_results_['std_score_time']

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=KFold(n_splits=10, random_...train_score=False, scoring='accuracy', verbose=0), X=       WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], y=6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, groups=None)
   1185             train/test set.
   1186         """
   1187         sampled_params = ParameterSampler(self.param_distributions,
   1188                                           self.n_iter,
   1189                                           random_state=self.random_state)
-> 1190         return self._fit(X, y, groups, sampled_params)
        self._fit = <bound method RandomizedSearchCV._fit of Randomi...rain_score=False, scoring='accuracy', verbose=0)>
        X =        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns]
        y = 6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64
        groups = None
        sampled_params = <sklearn.model_selection._search.ParameterSampler object>
   1191 
   1192 
   1193 
   1194 

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=KFold(n_splits=10, random_...train_score=False, scoring='accuracy', verbose=0), X=       WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], y=6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=16), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=16)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Tue Dec 11 03:43:22 2018
PID: 3300                                    Python 3.4.9: /usr/bin/python3
...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True),        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], 6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, make_scorer(accuracy_score), array([ 1627,  1628,  1629, ..., 16267, 16268, 16269]), array([   0,    1,    2, ..., 1624, 1625, 1626]), 0, {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 3, 'oob_score': True, 'warm_start': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': False})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True),        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], 6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, make_scorer(accuracy_score), array([ 1627,  1628,  1629, ..., 16267, 16268, 16269]), array([   0,    1,    2, ..., 1624, 1625, 1626]), 0, {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 3, 'oob_score': True, 'warm_start': True})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': False}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True), X=       WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[16270 rows x 1041 columns], y=6775     0
7566     1
17990    1
1180     4
1050...1      3
Name: FLOOR, Length: 16270, dtype: int64, scorer=make_scorer(accuracy_score), train=array([ 1627,  1628,  1629, ..., 16267, 16268, 16269]), test=array([   0,    1,    2, ..., 1624, 1625, 1626]), verbose=0, parameters={'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 3, 'oob_score': True, 'warm_start': True}, fit_params={}, return_train_score=False, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method BaggingClassifier.fit of BaggingCl...     random_state=7, verbose=0, warm_start=True)>
        X_train =        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[14643 rows x 1041 columns]
        y_train = 11757    1
289      3
1946     3
15119    0
1136...1      3
Name: FLOOR, Length: 14643, dtype: int64
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/ensemble/bagging.py in fit(self=BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True), X=       WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[14643 rows x 1041 columns], y=11757    1
289      3
1946     3
15119    0
1136...1      3
Name: FLOOR, Length: 14643, dtype: int64, sample_weight=None)
    243         Returns
    244         -------
    245         self : object
    246             Returns self.
    247         """
--> 248         return self._fit(X, y, self.max_samples, sample_weight=sample_weight)
        self._fit = <bound method BaggingClassifier._fit of BaggingC...     random_state=7, verbose=0, warm_start=True)>
        X =        WAP001  WAP002  WAP003  WAP004  WAP005   ...01             503  

[14643 rows x 1041 columns]
        y = 11757    1
289      3
1946     3
15119    0
1136...1      3
Name: FLOOR, Length: 14643, dtype: int64
        self.max_samples = 1.0
        sample_weight = None
    249 
    250     def _fit(self, X, y, max_samples=None, max_depth=None, sample_weight=None):
    251         """Build a Bagging ensemble of estimators from the training
    252            set (X, y).

...........................................................................
/usr/lib64/python3.4/site-packages/sklearn/ensemble/bagging.py in _fit(self=BaggingClassifier(base_estimator=DecisionTreeCla...      random_state=7, verbose=0, warm_start=True), X=array([[  0.,   0.,   0., ...,   1.,   1., 501.]...      [  0.,   0.,   0., ...,   1.,   1., 503.]]), y=array([1, 3, 3, ..., 0, 3, 3]), max_samples=14643, max_depth=None, sample_weight=None)
    322         if not self.bootstrap and self.oob_score:
    323             raise ValueError("Out of bag estimation only available"
    324                              " if bootstrap=True")
    325 
    326         if self.warm_start and self.oob_score:
--> 327             raise ValueError("Out of bag estimate only available"
    328                              " if warm_start=False")
    329 
    330         if hasattr(self, "oob_score_") and self.warm_start:
    331             del self.oob_score_

ValueError: Out of bag estimate only available if warm_start=False
___________________________________________________________________________
